{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79dc9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a0d647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>A48</th>\n",
       "      <th>A49</th>\n",
       "      <th>A50</th>\n",
       "      <th>A51</th>\n",
       "      <th>A52</th>\n",
       "      <th>A53</th>\n",
       "      <th>A54</th>\n",
       "      <th>A55</th>\n",
       "      <th>A56</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A0    A1    A2   A3    A4    A5    A6    A7    A8    A9  ...    A48  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "        A49  A50    A51    A52    A53    A54  A55   A56  label  \n",
       "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278      1  \n",
       "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028      1  \n",
       "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259      1  \n",
       "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191      1  \n",
       "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191      1  \n",
       "...     ...  ...    ...    ...    ...    ...  ...   ...    ...  \n",
       "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88      0  \n",
       "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14      0  \n",
       "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118      0  \n",
       "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78      0  \n",
       "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40      0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data=pd.read_csv(\"https://web.stanford.edu/~hastie/ElemStatLearn//datasets/spam.data\",sep=' ',header=None)\n",
    "name_list=[]\n",
    "for i in range(len(spam_data.columns)-1):\n",
    "    i_str= str(i)\n",
    "    name_list.append(\"A\"+i_str)\n",
    "name_list.append(\"label\")\n",
    "spam_data.columns=name_list\n",
    "spam_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32771e2",
   "metadata": {},
   "source": [
    "### Function Definitions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f47f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Is_Pure(data):\n",
    "    \n",
    "    label_column = data[:, -1] #extracting only the labels\n",
    "    unique_labels = np.unique(label_column)\n",
    "    if len(unique_labels) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569eae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassForPureData(data):  #This function is used to return the class label of the pure data set or it can also be used when we need to pick majority class from a data\n",
    "    \n",
    "    label_column = data[:, -1] \n",
    "    classlabels,classcounts=np.unique(label_column,return_counts=True)\n",
    "    majorityclassindex= np.argmax(classcounts)\n",
    "    classi= classlabels[majorityclassindex]\n",
    "\n",
    "    return classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51199c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits(data,ran_ss):\n",
    "    \n",
    "    splits = {} #creating an empty dictionary to store the splits with key of the dictionary as attribute index and values as various splits\n",
    "    row,col = data.shape #to get the number of columns to iterate over the columns\n",
    "    \n",
    "    column_indices= list(range(col-1)) #column indices as list\n",
    "    \n",
    "    if ran_ss and ran_ss<=len(column_indices):\n",
    "        column_indices= random.sample(population=column_indices, k=ran_ss)\n",
    "        \n",
    "    for i in column_indices:        # excluding the last column which is the quality label\n",
    "        splits[i] = []\n",
    "        tot_col = data[:, i] #to extract the total column of ith attribute\n",
    "        uni_val = np.unique(tot_col)  #to weed out the repeated or duplicate values of the column\n",
    "        splits[i]=uni_val\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e820935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, column_to_split, value_to_split):\n",
    "    \n",
    "    split_column_values = data[:, column_to_split]\n",
    "\n",
    "    left_data = data[split_column_values <= value_to_split]\n",
    "    right_data = data[split_column_values > value_to_split]\n",
    "    \n",
    "    return left_data, right_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eefb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    classlabels, classcounts = np.unique(label_column, return_counts=True) #extract the counts of classes in dataset\n",
    "    \n",
    "    #numpy does element wise operations. So probabilities and entropy can be calculated as\n",
    "    probab = classcounts/ classcounts.sum()\n",
    "    entropy = sum(probab * -np.log2(probab))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836014bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_entropy(ldata, rdata):\n",
    "    \n",
    "    tot_data = len(ldata) + len(rdata)\n",
    "    prob_ldata = len(ldata) / tot_data\n",
    "    prob_rdata = len(rdata) / tot_data\n",
    "\n",
    "    weigh_entro =  (prob_ldata * entropy(ldata) \n",
    "                      + prob_rdata * entropy(rdata))\n",
    "    \n",
    "    return weigh_entro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ed7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_entropy(data, potential_splits):\n",
    "    \n",
    "    arbit_entropy = 100\n",
    "    global best_split_column\n",
    "    global best_split_value\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_left, data_right = split_data(data, column_to_split=column_index, value_to_split=value)\n",
    "            presentweigh_entropy = weighted_entropy(data_left, data_right)\n",
    "\n",
    "            if presentweigh_entropy <= arbit_entropy:\n",
    "                arbit_entropy = presentweigh_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c005aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_algo_entropy(df, counter=0,ran_ss=None):\n",
    "    \n",
    "    # data preparations\n",
    "    min_samples=7\n",
    "    max_depth=20\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if Is_Pure(data) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = ClassForPureData(data)\n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = splits(data,ran_ss)\n",
    "        split_column, split_value = best_split_entropy(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = dtree_algo_entropy(data_below, counter, ran_ss)\n",
    "        no_answer = dtree_algo_entropy(data_above, counter, ran_ss)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base cases).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ccfc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_datapoint(data_point, model):  #This function gets input as each data point(i.e all the 11 features) and says the classification\n",
    "    ques = list(model.keys())[0]  #The tree is basically a dictionary with contains of a key and value basically. Here we are picking the first key which will be the dictionary\n",
    "    col_name, operator, value = ques.split()\n",
    "\n",
    "    if data_point[col_name] <= float(value):\n",
    "        ans = model[ques][0]                   #note: general form of tree is tree={question,[positive_answer,negative_answer]}\n",
    "    else:\n",
    "        ans = model[ques][1]\n",
    "\n",
    "    if isinstance(ans, dict): #checking if we narrow down at a class label or again a question in the form of dictionary\n",
    "        residual_tree = ans\n",
    "        return classify_datapoint(data_point, residual_tree)\n",
    "    else:\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c32e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_predictions(test_df, model):\n",
    "    predictions=test_df.apply(classify_datapoint, args=(model,),axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc856f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, labels):\n",
    "    predictions_correct = predictions == labels\n",
    "    accuracy = predictions_correct.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c11184",
   "metadata": {},
   "source": [
    "### Functions definitions pertaining to Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a64a369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(train_df, n_bootstrap):\n",
    "    index_list = train_df.index.tolist()\n",
    "    bootstra_indices = random.sample(population=index_list, k=n_bootstrap)\n",
    "    df_bootstrapped = train_df.loc[bootstra_indices]\n",
    "    df_oob = train_df.drop(bootstra_indices)\n",
    "    #print(df_bootstrapped.info(),df_oob.info())\n",
    "    return df_bootstrapped,df_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d907cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_algorithm(train_df, n_trees, n_bootstrap, n_features):\n",
    "    forest = []\n",
    "    for i in range(n_trees):\n",
    "        df_bootstrapped,df_oob= bootstrapping(train_df, n_bootstrap)\n",
    "        tree = dtree_algo_entropy(df_bootstrapped, ran_ss=n_features)\n",
    "        forest.append(tree)\n",
    "    \n",
    "    return forest,df_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36f94fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_predictions(test_df, forest):\n",
    "    df_predictions = {}\n",
    "    for i in range(len(forest)):\n",
    "        column_name = \"tree_{}\".format(i)\n",
    "        predictions = decision_tree_predictions(test_df, model=forest[i])\n",
    "        df_predictions[column_name] = predictions\n",
    "\n",
    "    df_predictions = pd.DataFrame(df_predictions)\n",
    "    random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
    "    \n",
    "    return random_forest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2a5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainandTest(df, testdatasize):\n",
    "\n",
    "    testdatasize = round(testdatasize * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_points = random.sample(population=indices, k=testdatasize)\n",
    "\n",
    "    test_set = df.loc[test_points]\n",
    "    train_set = df.drop(test_points)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f34f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_d,test_d= splitTrainandTest(spam_data, testdatasize=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e31c54",
   "metadata": {},
   "source": [
    "### Model building and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01f103d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using own implementation of random forest with m=20:  0.9231884057971015\n",
      "OOB error using own implementation of random forest with m=20:  0.047276001800990564\n",
      "Accuracy using sklearn implementation of random forest with m=20:  0.9355072463768116\n",
      "Sensitivity (a.k.a Recall) with m=20:  0.9111498257839721\n"
     ]
    }
   ],
   "source": [
    "#m=20\n",
    "\n",
    "forest1, df_oob1 = random_forest_algorithm(train_d, n_trees=5, n_bootstrap=1000, n_features=20)\n",
    "predictions1 = random_forest_predictions(test_d, forest1)\n",
    "oob_predictions1 = random_forest_predictions(df_oob1, forest1)\n",
    "accuracy1 = calculate_accuracy(predictions1, test_d.label)\n",
    "oob_accuracy1 = calculate_accuracy(oob_predictions1, df_oob1.label)\n",
    "print(\"Accuracy using own implementation of random forest with m=20: \",accuracy1)\n",
    "print(\"OOB error using own implementation of random forest with m=20: \",1-oob_accuracy1)\n",
    "\n",
    "#Splitting data to pass it to sklearn function\n",
    "X_train1 = train_d.iloc[:, :-1].values\n",
    "Y_train1= train_d.iloc[:, -1].values.reshape(-1,1)\n",
    "X_test1 = test_d.iloc[:, :-1].values\n",
    "Y_test1= test_d.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "#Random forest using sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "model1=RandomForestClassifier(n_estimators=5,criterion='entropy',max_depth=20, min_samples_split=7,max_features=20) #bootstrap default as True\n",
    "model1.fit(X_train1,Y_train1.ravel())\n",
    "Y_pred=model1.predict(X_test1)\n",
    "rs=recall_score(Y_test1,Y_pred)\n",
    "skscore=model1.score(X_test1,Y_test1)\n",
    "print(\"Accuracy using sklearn implementation of random forest with m=20: \",skscore)\n",
    "print(\"Sensitivity (a.k.a Recall) with m=20: \",rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de989684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using own implementation of random forest with m=25:  0.9173913043478261\n",
      "OOB error using own implementation of random forest with m=25:  0.048626744709590275\n",
      "Accuracy using sklearn implementation of random forest with m=25:  0.9282608695652174\n",
      "Sensitivity (a.k.a Recall) with m=25:  0.9041811846689896\n"
     ]
    }
   ],
   "source": [
    "#m=25\n",
    "\n",
    "forest1, df_oob1 = random_forest_algorithm(train_d, n_trees=5, n_bootstrap=1000, n_features=25)\n",
    "predictions1 = random_forest_predictions(test_d, forest1)\n",
    "oob_predictions1 = random_forest_predictions(df_oob1, forest1)\n",
    "accuracy1 = calculate_accuracy(predictions1, test_d.label)\n",
    "oob_accuracy1 = calculate_accuracy(oob_predictions1, df_oob1.label)\n",
    "print(\"Accuracy using own implementation of random forest with m=25: \",accuracy1)\n",
    "print(\"OOB error using own implementation of random forest with m=25: \",1-oob_accuracy1)\n",
    "\n",
    "#Splitting data to pass it to sklearn function\n",
    "X_train1 = train_d.iloc[:, :-1].values\n",
    "Y_train1= train_d.iloc[:, -1].values.reshape(-1,1)\n",
    "X_test1 = test_d.iloc[:, :-1].values\n",
    "Y_test1= test_d.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "#Random forest using sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1=RandomForestClassifier(n_estimators=5,criterion='entropy',max_depth=20, min_samples_split=7,max_features=25) #bootstrap default as True\n",
    "model1.fit(X_train1,Y_train1.ravel())\n",
    "Y_pred=model1.predict(X_test1)\n",
    "rs=recall_score(Y_test1,Y_pred)\n",
    "skscore=model1.score(X_test1,Y_test1)\n",
    "print(\"Accuracy using sklearn implementation of random forest with m=25: \",skscore)\n",
    "print(\"Sensitivity (a.k.a Recall) with m=25: \",rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe653f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using own implementation of random forest with m=30:  0.9181159420289855\n",
      "OOB error using own implementation of random forest with m=30:  0.05042773525438993\n",
      "Accuracy using sklearn implementation of random forest with m=30:  0.922463768115942\n",
      "Sensitivity (a.k.a Recall) with m=30:  0.8902439024390244\n"
     ]
    }
   ],
   "source": [
    "#m=30\n",
    "\n",
    "forest1, df_oob1 = random_forest_algorithm(train_d, n_trees=5, n_bootstrap=1000, n_features=30)\n",
    "predictions1 = random_forest_predictions(test_d, forest1)\n",
    "oob_predictions1 = random_forest_predictions(df_oob1, forest1)\n",
    "accuracy1 = calculate_accuracy(predictions1, test_d.label)\n",
    "oob_accuracy1 = calculate_accuracy(oob_predictions1, df_oob1.label)\n",
    "print(\"Accuracy using own implementation of random forest with m=30: \",accuracy1)\n",
    "print(\"OOB error using own implementation of random forest with m=30: \",1-oob_accuracy1)\n",
    "\n",
    "#Splitting data to pass it to sklearn function\n",
    "X_train1 = train_d.iloc[:, :-1].values\n",
    "Y_train1= train_d.iloc[:, -1].values.reshape(-1,1)\n",
    "X_test1 = test_d.iloc[:, :-1].values\n",
    "Y_test1= test_d.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "#Random forest using sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1=RandomForestClassifier(n_estimators=5,criterion='entropy',max_depth=20, min_samples_split=7,max_features=30) #bootstrap default as True\n",
    "model1.fit(X_train1,Y_train1.ravel())\n",
    "Y_pred=model1.predict(X_test1)\n",
    "rs=recall_score(Y_test1,Y_pred)\n",
    "skscore=model1.score(X_test1,Y_test1)\n",
    "print(\"Accuracy using sklearn implementation of random forest with m=30: \",skscore)\n",
    "print(\"Sensitivity (a.k.a Recall) with m=30: \",rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64dff2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using own implementation of random forest with m=35:  0.9195652173913044\n",
      "OOB error using own implementation of random forest with m=35:  0.04592525889239085\n",
      "Accuracy using sklearn implementation of random forest with m=35:  0.9326086956521739\n",
      "Sensitivity (a.k.a Recall) with m=35:  0.9111498257839721\n"
     ]
    }
   ],
   "source": [
    "#m=35\n",
    "\n",
    "forest1, df_oob1 = random_forest_algorithm(train_d, n_trees=5, n_bootstrap=1000, n_features=35)\n",
    "predictions1 = random_forest_predictions(test_d, forest1)\n",
    "oob_predictions1 = random_forest_predictions(df_oob1, forest1)\n",
    "accuracy1 = calculate_accuracy(predictions1, test_d.label)\n",
    "oob_accuracy1 = calculate_accuracy(oob_predictions1, df_oob1.label)\n",
    "print(\"Accuracy using own implementation of random forest with m=35: \",accuracy1)\n",
    "print(\"OOB error using own implementation of random forest with m=35: \",1-oob_accuracy1)\n",
    "\n",
    "#Splitting data to pass it to sklearn function\n",
    "X_train1 = train_d.iloc[:, :-1].values\n",
    "Y_train1= train_d.iloc[:, -1].values.reshape(-1,1)\n",
    "X_test1 = test_d.iloc[:, :-1].values\n",
    "Y_test1= test_d.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "#Random forest using sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1=RandomForestClassifier(n_estimators=5,criterion='entropy',max_depth=20, min_samples_split=7,max_features=35) #bootstrap default as True\n",
    "model1.fit(X_train1,Y_train1.ravel())\n",
    "Y_pred=model1.predict(X_test1)\n",
    "rs=recall_score(Y_test1,Y_pred)\n",
    "skscore=model1.score(X_test1,Y_test1)\n",
    "print(\"Accuracy using sklearn implementation of random forest with m=35: \",skscore)\n",
    "print(\"Sensitivity (a.k.a Recall) with m=35: \",rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a796a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using own implementation of random forest with m=40:  0.9239130434782609\n",
      "OOB error using own implementation of random forest with m=40:  0.04547501125619091\n",
      "Accuracy using sklearn implementation of random forest with m=40:  0.922463768115942\n",
      "Sensitivity (a.k.a Recall) with m=40:  0.9006968641114983\n"
     ]
    }
   ],
   "source": [
    "#m=40\n",
    "\n",
    "forest1, df_oob1 = random_forest_algorithm(train_d, n_trees=5, n_bootstrap=1000, n_features=40)\n",
    "predictions1 = random_forest_predictions(test_d, forest1)\n",
    "oob_predictions1 = random_forest_predictions(df_oob1, forest1)\n",
    "accuracy1 = calculate_accuracy(predictions1, test_d.label)\n",
    "oob_accuracy1 = calculate_accuracy(oob_predictions1, df_oob1.label)\n",
    "print(\"Accuracy using own implementation of random forest with m=40: \",accuracy1)\n",
    "print(\"OOB error using own implementation of random forest with m=40: \",1-oob_accuracy1)\n",
    "\n",
    "#Splitting data to pass it to sklearn function\n",
    "X_train1 = train_d.iloc[:, :-1].values\n",
    "Y_train1= train_d.iloc[:, -1].values.reshape(-1,1)\n",
    "X_test1 = test_d.iloc[:, :-1].values\n",
    "Y_test1= test_d.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "#Random forest using sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1=RandomForestClassifier(n_estimators=5,criterion='entropy',max_depth=20, min_samples_split=7,max_features=40) #bootstrap default as True\n",
    "model1.fit(X_train1,Y_train1.ravel())\n",
    "Y_pred=model1.predict(X_test1)\n",
    "rs=recall_score(Y_test1,Y_pred)\n",
    "skscore=model1.score(X_test1,Y_test1)\n",
    "print(\"Accuracy using sklearn implementation of random forest with m=40: \",skscore)\n",
    "print(\"Sensitivity (a.k.a Recall) with m=40: \",rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bff49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234b98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83084d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed33260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
